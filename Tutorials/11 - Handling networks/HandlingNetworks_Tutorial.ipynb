{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```\n",
    "pip install networkx python-louvain\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependendencies\n",
    "\n",
    "!pip install networkx python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from community import community_louvain\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducting Networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX has a broad range of example networks that you can load with just a function call ([more examples here](https://networkx.github.io/documentation/stable/auto_examples/index.html)).\n",
    "\n",
    ".. and a super friendly API that you can use to conviently build networks.\n",
    "\n",
    "In order to get used to NetworkX API, let's just construct a simple **undirected graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Visualizing a simple Undirected Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph() # for a directed graph use nx.DiGraph()\n",
    "G.add_node(1)\n",
    "G.add_nodes_from(range(2,9))  # add multiple nodes at once\n",
    "\n",
    "# add edges \n",
    "G.add_edge(1,2)\n",
    "edges = [(2,3), (1,3), (4,1), (4,5), (5,6), (5,7), (6,7), (7,8), (6,8)]\n",
    "G.add_edges_from(edges)\n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you like to get a quick overview of your dataset using `.describe()` in pandas ?\n",
    "Here is the equivalent in NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library also has a built-in plotting engine (based on matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it out\n",
    "# for different layouts, please see: https://networkx.github.io/documentation/stable/reference/drawing.html#module-networkx.drawing.layout\n",
    "nx.draw_spring(G, with_labels=True,  alpha = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting the degree distribution of a Graph\n",
    "def plot_degree_distribution(G):\n",
    "    degrees = {}\n",
    "    for node in G.nodes():\n",
    "        degree = G.degree(node)\n",
    "        if degree not in degrees:\n",
    "            degrees[degree] = 0\n",
    "        degrees[degree] += 1\n",
    "    sorted_degree = sorted(degrees.items())\n",
    "    deg = [k for (k,v) in sorted_degree]\n",
    "    cnt = [v for (k,v) in sorted_degree]\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.80, color='b')\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "    ax.set_xticks([d+0.05 for d in deg])\n",
    "    ax.set_xticklabels(deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing various graph properties\n",
    "def describe_graph(G):\n",
    "    print(nx.info(G))\n",
    "    if nx.is_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" %nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" %nx.diameter(G)) # Longest shortest path\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "    print(\"Sparsity: %.4f\" %nx.density(G))  # #edges/#edges-complete-graph\n",
    "    # #closed-triplets(3*#triangles)/#all-triplets\n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" %nx.transitivity(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualizing the graph\n",
    "def visualize_graph(G, with_labels=True, k=None, alpha=1.0, node_shape='o'):\n",
    "    #nx.draw_spring(G, with_labels=with_labels, alpha = alpha)\n",
    "    pos = nx.spring_layout(G, k=k)\n",
    "    if with_labels:\n",
    "        lab = nx.draw_networkx_labels(G, pos, labels=dict([(n, n) for n in G.nodes()]))\n",
    "    ec = nx.draw_networkx_edges(G, pos, alpha=alpha)\n",
    "    nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color='g', node_shape=node_shape)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Visualizing an Erdős–Rényi graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 10  # 10 nodes\n",
    "m = 20  # 20 edges\n",
    "\n",
    "erG = nx.gnm_random_graph(n, m)\n",
    "\n",
    "describe_graph(erG)\n",
    "visualize_graph(erG, k=0.05, alpha=0.8)\n",
    "plot_degree_distribution(erG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Visualizing the Zachary's Karate Club Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "karateG = nx.karate_club_graph()\n",
    "describe_graph(karateG)\n",
    "visualize_graph(karateG, k=0.05, alpha=0.8)\n",
    "plot_degree_distribution(karateG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph with a circular layout instead?\n",
    "nx.draw_circular(karateG, with_labels=True,  node_color='g', alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Quakers !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now go beyond toy examples and load real data! \n",
    "\n",
    "England, in the mid-17th century. A novel group of Protestant Christians, called \"Religious Society of Friends\" dissent from the main doctrine. Their members are known as the \"Quakers\". This dataset is derived from the [\"Oxford Dictionary of National Biography\"](http://www.oxforddnb.com/) and from the ongoing work of the *\"Six Degrees of Francis Bacon project\"*, which is reconstructing the social networks of early modern Britain (1500-1700) to trace the personal relationships among figures like **Bacon**, **Shakespeare**, **Sir Isaac Newton** and many others.\n",
    "\n",
    "[Credits](https://programminghistorian.org/en/lessons/exploring-and-analyzing-network-data-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meet the Quakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/quakers/'\n",
    "nodes = pd.read_csv(data_folder + 'quakers_nodelist.csv')\n",
    "nodes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.Gender = nodes.Gender.astype('category')\n",
    "nodes = nodes.rename({'Historical Significance': 'Role'}, axis = 1)\n",
    "print('There are ', len(nodes), 'quakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['Role'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some don't have a known 'historical significance' or 'role'\n",
    "nodes['Role'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the names are unique\n",
    "len(nodes['Name'].unique()) == len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the names are unique, index based on names\n",
    "nodes.set_index('Name', inplace=True)\n",
    "\n",
    "# let's also add a new attribute based on the role column. Is (s)he a directly involved Quaker or not? \n",
    "nodes['Quaker'] = ['quaker' in role.lower() for role in nodes.Role]\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see which quaker knows whom, this will translate into edges in our graph\n",
    "edges = pd.read_csv(data_folder + 'quakers_edgelist.csv')\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are',len(edges), 'edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Quaker network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients and more to translate this data into a network: nodes are the quakers and there exists an edge between two quakers if they know each other. Since being acquainted or friends is a symmetric relation, we will build an undirected graph.\n",
    "\n",
    "Another bonus of NetworkX is the smooth integration with panda dataframes, which makes loading the network a one-liner.   \n",
    "*Note: Only if you don't have isolated nodes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakerG =nx.from_pandas_edgelist(edges, 'Source', 'Target', edge_attr=None, create_using= nx.Graph())\n",
    "describe_graph(quakerG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node attributes by passing dictionary of type name -> attribute\n",
    "nx.set_node_attributes(quakerG, nodes['Role'].to_dict(), 'Role' )\n",
    "nx.set_node_attributes(quakerG, nodes['Gender'].to_dict(), 'Gender' )\n",
    "nx.set_node_attributes(quakerG, nodes['Birthdate'].to_dict(), 'Birthdate' )\n",
    "nx.set_node_attributes(quakerG, nodes['Deathdate'].to_dict(), 'Deathdate' )\n",
    "nx.set_node_attributes(quakerG, nodes['Quaker'].to_dict(), 'Quaker' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can easily get the attributes of a node\n",
    "quakerG.nodes['William Penn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How connected is the quaker network ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel of the network, we could start by visually inspecting the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(quakerG, False, k=0.05, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make the visualization a bit better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(quakerG, False, k=0.2, alpha=0.4, node_shape='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not a very pretty visualisation (.. install  [Gephy](https://gephi.org/) for some better-looking plots). However, a few things come across:\n",
    "\n",
    "* The graph is not connected (there are a few isolated communities)\n",
    "* There seem to be a few nodes with many connections (i.e. hubs)\n",
    "\n",
    "That's as far as we can get, let's revert to **numbers and graph properties** for more insights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity\n",
    "\"Sparsity\" of a graph with $n$ nodes is defined as follows: \n",
    "\n",
    "$ L = \\frac{|E|}{|E_{max}|}$, where $E_{max} = \\frac{n * (n-1)}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 174 * (2) / ( 119* 118)\n",
    "print(\"Network sparsity: %.4f\" %nx.density(quakerG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Components\n",
    "If the graph is not connected, how many \"connected components\" are there ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.is_connected(quakerG))\n",
    "comp = list(nx.connected_components(quakerG))\n",
    "print('The graph contains', len(comp), 'connected components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_comp = max(comp, key=len)\n",
    "percentage_lcc = len(largest_comp)/quakerG.number_of_nodes() * 100\n",
    "print('The largest component has', len(largest_comp), 'nodes', 'accounting for %.2f'% percentage_lcc, '% of the nodes') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visually inspecting the graph, we already saw that most of the nodes are in the largest component, which is often the case in a graph. That is why we usually call this component as a **giant component**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diameter and Shortest Paths\n",
    "Suppose I want to find the shortest path between two quakers, given that they are in the same connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fell_whitehead_path = nx.shortest_path(quakerG, source=\"Margaret Fell\", target=\"George Whitehead\")\n",
    "print(\"Shortest path between Fell and Whitehead:\", fell_whitehead_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the largest component and analyse its diameter = longest shortest-path\n",
    "lcc_quakerG = quakerG.subgraph(largest_comp)\n",
    "print(\"The diameter of the largest connected component is\", nx.diameter(lcc_quakerG))\n",
    "print(\"The avg shortest path length of the largest connected component is\", nx.average_shortest_path_length(lcc_quakerG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more social look at the network!\n",
    "\n",
    "**Triadic Closure:**   \n",
    "    A *friend* of my *friend* is my *friend*   \n",
    "    OR   \n",
    "    *quaker_1* knows *quaker_2* and *quaker_2* knows *quaker_3*, how likely is that *quaker_1* and *quaker_3* know each other?\n",
    "\n",
    "Employ a **global** measure called **transitivity** (aka global clustering coefficient), or the ratio of all existing triangles (closed triples) over all possible triangles (open and closed triplets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.4f' %nx.transitivity(quakerG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employ a **local** measure called **clustering coefficient**, which quantifies for a node how close its neighbours are to being a clique (complete graph). Measured as the ratio of, the number of edges to the number of all possible edges, among the neighbors of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar measure but for individual nodes called clustering coefficient\n",
    "print(nx.clustering(quakerG, ['Alexander Parker', 'John Crook']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check by looking at the subgraphs induced by Alex and John\n",
    "subgraph_Alex = quakerG.subgraph(['Alexander Parker']+list(quakerG.neighbors('Alexander Parker')))\n",
    "subgraph_John = quakerG.subgraph(['John Crook']+list(quakerG.neighbors('John Crook')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(subgraph_Alex, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx.draw_circular(subgraph_John, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which quakers are the most important ?\n",
    "\n",
    "As always, the answer is ... it depends. There are many ways to detect important nodes in a graph, for example based on:\n",
    "\n",
    "* **Degree** (generalized by **Katz**)\n",
    "* **Betweeness centrality**\n",
    "* More ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree: the more people you know, the more important you are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "sorted_degree = sorted(degrees.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, degree in sorted_degree[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'knows', degree, 'people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also analyze the *degree distribution*. \n",
    "We can see that most of the people know less than 5 quakers and there are some *leaders that are comparatively very popular*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_seq = [d[1] for d in sorted_degree]\n",
    "degreeCount = collections.Counter(degree_seq)\n",
    "degreeCount = pd.DataFrame.from_dict( degreeCount, orient='index').reset_index()\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(degreeCount['index'], degreeCount[0], 'o', c='blue', markersize= 4)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Degree')\n",
    "plt.title('Degree distribution for the Quaker network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a bar plot\n",
    "plot_degree_distribution(quakerG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about the Katz Centrality (the generalization over degree centrality)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "\n",
    "katz = nx.katz_centrality(quakerG)\n",
    "nx.set_node_attributes(quakerG, katz, 'katz')\n",
    "sorted_katz = sorted(katz.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, katzc in sorted_katz[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has katz-centrality: %.3f' %katzc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is an undirected graph. If you were to have a **directed** one, use separate metrics for **indegree** and **outdegree**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweeness centrality: the more shortest paths pass through a node, the more important it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(quakerG)\n",
    "# Assign the computed centrality values as a node-attribute in your network\n",
    "nx.set_node_attributes(quakerG, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for quaker, bw in sorted_betweenness[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the betweeness centrality values for all the nodes in the network. As in the case with degree, there are a *few nodes with very high betweeness centrality*, while most of them have a low value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# similar pattern\n",
    "list_nodes =list(quakerG.nodes())\n",
    "list_nodes.reverse()   # for showing the nodes with high betweeness centrality \n",
    "pos = nx.spring_layout(quakerG)\n",
    "ec = nx.draw_networkx_edges(quakerG, pos, alpha=0.1)\n",
    "nc = nx.draw_networkx_nodes(quakerG, pos, nodelist=list_nodes, node_color=[quakerG.nodes[n][\"betweenness\"] for n in list_nodes], \n",
    "                            alpha=0.8, node_shape = '.')\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you might be tempted to think the measures are very similar, but let's revisit the original graph (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, nx.betweenness_centrality(G), 'betweenness')\n",
    "pos = nx.spring_layout(G)\n",
    "ec = nx.draw_networkx(G, pos, nodelist=G.nodes(),\n",
    "                         node_color=[G.nodes[n][\"betweenness\"] for n in G.nodes()], \n",
    "                         node_shape = '.', node_size=1200, font_color=\"white\", font_weight=\"bold\")\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node with the **lowest degree** is the one with the **highest betweeness centrality**. \n",
    "\n",
    "This concept also translates to edges. In particular, edge betweeness is the number of shortest paths that pass through an edge. This brings us to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The quaker communities\n",
    "\n",
    "Community detection is a common class of methods applied to graphs. \n",
    "Two important algorithms:\n",
    "* **Girvan Newman**\n",
    "* **Louvain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Girvan Newman\n",
    "**Idea:** Edges possessing high betweeness centrality separate communities. Let's apply this on our toy sample graph (G) to get a better understanding of the idea.\n",
    "\n",
    "The algorithm starts with the entire graph and then it iteratively removes the edge with the highest betweeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = girvan_newman(G)\n",
    "it = 0\n",
    "for communities in itertools.islice(comp, 4):\n",
    "    it +=1\n",
    "    print('Iteration', it)\n",
    "    print(tuple(sorted(c) for c in communities)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(G,alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The [Louvain method](https://en.wikipedia.org/wiki/Louvain_Modularity)\n",
    "\n",
    "Another clustering algorithm and has become a standard algorithm in the data scientist toolbox.   \n",
    "**Idea:** It proceeds the other way around: initially every node is considered as a community. The communities are traversed, and for each community it is tested whether by joining it to a neighboring community, we can obtain a better clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community_louvain.best_partition(quakerG)\n",
    "# add it as an attribute to the nodes\n",
    "for n in quakerG.nodes:\n",
    "    quakerG.nodes[n][\"louvain\"] = partition[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it out\n",
    "pos = nx.spring_layout(quakerG,k=0.2)\n",
    "ec = nx.draw_networkx_edges(quakerG, pos, alpha=0.2)\n",
    "nc = nx.draw_networkx_nodes(quakerG, pos, nodelist=quakerG.nodes(), node_color=[quakerG.nodes[n][\"louvain\"] for n in quakerG.nodes], \n",
    "                            node_size=100, cmap=plt.cm.jet)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a closer look at a few clusters and show their member's role and period in which they lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_James = partition['James Nayler']\n",
    "# Take all the nodes that belong to James' cluster\n",
    "members_c = [q for q in quakerG.nodes if partition[q] == cluster_James]\n",
    "# get info about these quakers\n",
    "for quaker in members_c:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'and died in ',quakerG.nodes[quaker]['Deathdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_Lydia = partition['Lydia Lancaster']\n",
    "# Take all the nodes that belong to Lydia's cluster\n",
    "members_c = [q for q in quakerG.nodes if partition[q] == cluster_Lydia]\n",
    "# get info about these quakers\n",
    "for quaker in members_c:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'and died in ',quakerG.nodes[quaker]['Deathdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homophily in quakers \n",
    "How likely is it that two quakers who have the same attribute are linked?\n",
    "\n",
    "Try to measure the similarity of connections in the graph with respect to a given attribute.   \n",
    "*Intuition: Like correlation, but translated to graphs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical attributes\n",
    "nx.attribute_assortativity_coefficient(quakerG, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.groupby('Gender').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no notion of *gender homophily* in this network, which makes sense due to the following:\n",
    "* Couples\n",
    "* Gender imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there exists **age homophily**: quakers that died in the same period are more likely to be linked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical attributes, values must be integers\n",
    "nx.numeric_assortativity_coefficient(quakerG, 'Deathdate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Exercises\n",
    "1. Visually determine the diameter of the small graph we built at the beginning (G) and then check you got it right.\n",
    "2. Experiment with the Girvan Newman algorithm on the Quaker (quakerG) network.\n",
    "3. Compute role homophily in the Quaker network.   \n",
    "*Hint: You can either do it based on the given roles you have or develop a more coarse categorisation of roles and repeat your analysis after.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take it further \n",
    "Course at Stanford taught by Jure Leskovec: http://web.stanford.edu/class/cs224w/\n",
    "\n",
    "(Better) alternative to NetworkX, see igraph: http://igraph.org/python/\n",
    "\n",
    "For larger graph analysis:\n",
    "\n",
    "* Apache GraphX: https://spark.apache.org/graphx/\n",
    "* Apache Giraph: http://giraph.apache.org\n",
    "* Webgraph: http://webgraph.di.unimi.it/\n",
    "* SNAP: http://snap.stanford.edu/snap/\n",
    "* Graph tool: https://graph-tool.skewed.de\n",
    "* Network kit: https://networkit.iti.kit.edu/api/structures.html\n",
    "* Pajek: http://mrvar.fdv.uni-lj.si/pajek/\n",
    "* Network Workbench: http://nwb.cns.iu.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
