{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"\"\n",
    "episode = \"\"\n",
    "scene = \"\"\n",
    "data = []\n",
    "with open(\"data/all_scripts.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line[:-1]\n",
    "        if line.startswith(\">> \"):\n",
    "            season = int(line[10:12])\n",
    "            episode = line[3:]\n",
    "            continue\n",
    "        if line.startswith(\"> \"):\n",
    "            scene = line[2:]\n",
    "            continue\n",
    "        character, line = line.split(\": \", 1)\n",
    "        data.append([season, episode, scene, character, line])\n",
    "lines = pd.DataFrame(data, columns=[\"Season\", \"Episode\", \"Scene\", \"Character\", \"Line\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,figsize=(7, 7), sharex = True, sharey = True)\n",
    "axs.scatter(prop_20_matched['ratings_treat'],prop_20_matched['ratings_not'])\n",
    "axs.update({'xlabel':'Treatment Ratings', 'ylabel':'Control Ratings', 'title':'Ratings Scatterplot'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(10, 3), sharex = True, sharey = True)\n",
    "sns.histplot(x = prop_20_matched['ratings_treat'], stat=\"density\", bins = 13, ax = axs[0])\n",
    "sns.histplot(x = prop_20_matched['ratings_not'], stat=\"density\",bins = 13, ax = axs[1])\n",
    "sns.histplot(x = prop_20_not['ratings'], stat=\"density\", bins = 13, ax = axs[2])\n",
    "\n",
    "axs[0].set_xlabel('Treatment')\n",
    "axs[1].set_xlabel('Control - Matched')\n",
    "axs[2].set_xlabel('Control - All')\n",
    "fig.suptitle('Ratings Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "#the grid of regularization parameter \n",
    "grid = [0.01,0.1,1,10,100,1000,10000]\n",
    "\n",
    "for c in grid:\n",
    "    \n",
    "    #initialize the classifier\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',C = c)\n",
    "    \n",
    "    #crossvalidate\n",
    "    scores = cross_val_score(clf, X_train,Y_train, cv=10)\n",
    "    accs.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hist, w_bins = np.histogram(df_distribution_bright['distance_from_home'], bins = np.logspace(0,5,50), density=True)\n",
    "w_bin_centers = w_bins[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(11,4))\n",
    "axs[0].plot(w_bin_centers, w_hist)\n",
    "axs[1].plot(w_bin_centers, np.cumsum(w_hist))\n",
    "axs[2].plot(w_bin_centers, w_hist)\n",
    "\n",
    "#axs[0].set_yscale(\"log\")\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[1].set_yscale(\"log\")\n",
    "axs[1].set_xscale(\"log\")\n",
    "axs[2].set_yscale(\"log\")\n",
    "axs[2].set_xscale(\"log\")\n",
    "\n",
    "axs[0].set_title('PDF')\n",
    "axs[1].set_title('CDF')\n",
    "axs[2].set_title('Log Log PDF')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and Apply Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bright.groupby(['user',pd.Grouper(key=\"local_time_grouper\",\n",
    "                                                              freq=\"1D\")]).agg({'distance_from_home': 'mean'})\n",
    "\n",
    "df_bright.groupby(['user',pd.Grouper(key=\"local_time_grouper\", \n",
    "                                              freq=\"1D\")]).agg({'season':'max',\n",
    "                                                                'distance_from_home': 'mean'}).groupby('season')['distance_from_home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bright['local_time_grouper'] = pd.to_datetime(df_bright['local_time_grouper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split string by spaces\n",
    "lines[\"Words\"] = lines[\"Line\"].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_frequency = pd.concat([pd.Series(row['Line'].split(' ')) for _, row in lines.iterrows()]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swap items in dict (needs to be set of both otherwise won't work)\n",
    "{f:n for n,f in enumerate(our_books.fileids())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='time ~ C(diabetes) + C(high_blood_pressure)', data=df)\n",
    "\n",
    "# Fits the model (find the optimal coefficients, adding a random seed ensures consistency)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit is logistic regression. The other parameters are the same as before\n",
    "\n",
    "mod = smf.logit(formula='DEATH_EVENT ~  age + creatinine_phosphokinase + ejection_fraction + \\\n",
    "                        platelets + serum_creatinine + serum_sodium + \\\n",
    "                        C(diabetes) + C(high_blood_pressure) +\\\n",
    "                        C(sex) + C(anaemia) + C(smoking) + C(high_blood_pressure)', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(accept_2020, reject_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y,test_size = test_size, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of regressor\n",
    "gb = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "# settings\n",
    "parameters = {'n_estimators': [50, 75, 100, 150, 200, 250],\n",
    "              'learning_rate': [.1, .05, .01]}\n",
    "y = df['ratings']\n",
    "X = df.drop('ratings',axis=1)\n",
    "X = df[NEW_FEATURES]\n",
    "\n",
    "# splitting the train and test dataset\n",
    "X_train, X_test, y_train, y_test = split_data_randomly(X,y,test_size = .3, random_state = 1 )\n",
    "\n",
    "# cross k validation using GridsearchCV\n",
    "clf = model_selection.GridSearchCV(gb, parameters, cv = 20, scoring = 'r2')\n",
    "clf.fit(X_train,y_train)\n",
    "best_param = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction of the confidence interval for each split\n",
    "\n",
    "confidence_interval=[]\n",
    "for i in range(result.shape[0]):\n",
    "    ci = sorted(result.loc[i,:])\n",
    "    confidence_interval.append([ci[1],ci[18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model for our best parameter\n",
    "optimal_reg = ensemble.GradientBoostingRegressor(**best_param).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction and R2\n",
    "pred = optimal_reg.predict(X_test)\n",
    "r2 = metrics.r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[lines[\"Character\"].isin(recurrent_characters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting the degree distribution of a Graph\n",
    "def plot_degree_distribution(G):\n",
    "    degrees = {}\n",
    "    for node in G.nodes():\n",
    "        degree = G.degree(node)\n",
    "        if degree not in degrees:\n",
    "            degrees[degree] = 0\n",
    "        degrees[degree] += 1\n",
    "    sorted_degree = sorted(degrees.items())\n",
    "    deg = [k for (k,v) in sorted_degree]\n",
    "    cnt = [v for (k,v) in sorted_degree]\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.80, color='b')\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "    ax.set_xticks([d+0.05 for d in deg])\n",
    "    ax.set_xticklabels(deg)\n",
    "    \n",
    "# Helper function for printing various graph properties\n",
    "def describe_graph(G):\n",
    "    print(nx.info(G))\n",
    "    if nx.is_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" %nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" %nx.diameter(G)) # Longest shortest path\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "    print(\"Sparsity: %.4f\" %nx.density(G))  # #edges/#edges-complete-graph\n",
    "    # #closed-triplets(3*#triangles)/#all-triplets\n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" %nx.transitivity(G))\n",
    "    \n",
    "# Helper function for visualizing the graph\n",
    "def visualize_graph(G, with_labels=True, k=None, alpha=1.0, node_shape='o'):\n",
    "    #nx.draw_spring(G, with_labels=with_labels, alpha = alpha)\n",
    "    pos = nx.spring_layout(G, k=k)\n",
    "    if with_labels:\n",
    "        lab = nx.draw_networkx_labels(G, pos, labels=dict([(n, n) for n in G.nodes()]))\n",
    "    ec = nx.draw_networkx_edges(G, pos, alpha=alpha)\n",
    "    nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color='g', node_shape=node_shape)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from pandas dataframe\n",
    "quakerG =nx.from_pandas_edgelist(edges, 'Source', 'Target', edge_attr=None, create_using= nx.Graph())\n",
    "describe_graph(quakerG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANCE\n",
    "#* **Degree** (generalized by **Katz**)\n",
    "#* **Betweeness centrality**\n",
    "\n",
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "sorted_degree = sorted(degrees.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, degree in sorted_degree[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'knows', degree, 'people')\n",
    "    \n",
    "\n",
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "\n",
    "katz = nx.katz_centrality(quakerG)\n",
    "nx.set_node_attributes(quakerG, katz, 'katz')\n",
    "sorted_katz = sorted(katz.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, katzc in sorted_katz[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has katz-centrality: %.3f' %katzc)\n",
    "    \n",
    "# Compute betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(quakerG)\n",
    "# Assign the computed centrality values as a node-attribute in your network\n",
    "nx.set_node_attributes(quakerG, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for quaker, bw in sorted_betweenness[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in common_scenes:\n",
    "    familiarity_graph.add_edge(key[0], key[1], weight=common_scenes[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bombing_Operations.registerTempTable(\"Bombing_Operations\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ContryFlyingMission, count(*) as MissionsCount\n",
    "FROM Bombing_Operations\n",
    "GROUP BY ContryFlyingMission\n",
    "ORDER BY MissionsCount DESC\n",
    "\"\"\"\n",
    "\n",
    "missions_counts = spark.sql(query)\n",
    "missions_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missions_counts = Bombing_Operations.groupBy(\"ContryFlyingMission\")\\\n",
    "                                    .agg(count(\"*\").alias(\"MissionsCount\"))\\\n",
    "                                    .sort(desc(\"MissionsCount\"))\n",
    "missions_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
